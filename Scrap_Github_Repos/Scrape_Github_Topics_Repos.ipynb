{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2c2de7",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories for Topics on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8c4f5",
   "metadata": {},
   "source": [
    "Here are the steps we'll follow:\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the top 25 repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6a5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_url = 'https://github.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4f67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c206b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topics_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6486757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    \n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "        \n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293678e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f7aac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_description(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_desc = []\n",
    "    \n",
    "    for tag in topic_desc_tags:\n",
    "        topic_desc.append(tag.text.strip())\n",
    "        \n",
    "    return topic_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f7028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = get_topic_description(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d82717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    topic_urls = []\n",
    "    \n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "        \n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1462ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e90189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = {'Topic_Title': titles, 'Topic_description': descriptions, 'Topic_url': urls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099eba33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Title</th>\n",
       "      <th>Topic_description</th>\n",
       "      <th>Topic_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D refers to the use of three-dimensional grap...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_Title                                  Topic_description  \\\n",
       "0          3D  3D refers to the use of three-dimensional grap...   \n",
       "1        Ajax  Ajax is a technique for creating interactive w...   \n",
       "2   Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3         Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4     Android  Android is an operating system built by Google...   \n",
       "\n",
       "                             Topic_url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = pd.DataFrame(topics_dict)\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22c186d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.to_csv('./Scrap_Github_Repos/Github_Topics.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09bc35d",
   "metadata": {},
   "source": [
    "# Get the top 20 repositories from a topic page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb530a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    response = requests.get(topic_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0fe357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars):\n",
    "    stars=stars.strip()\n",
    "    \n",
    "    if stars[-1]=='k':\n",
    "        return int(float(stars[:-1])*1000)\n",
    "    \n",
    "    return(int(stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69872d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h3_tag, star_tag):\n",
    "    \n",
    "    # returns all the required info about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url =  base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    \n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e735309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h1 tags containing repo title, repo URL and username\n",
    "    repo_tags = topic_doc.find_all('h3',{'class':'f3 color-fg-muted text-normal lh-condensed'})\n",
    "\n",
    "    # Get star tags\n",
    "    star_tags=topic_doc.find_all('span',{'id':'repo-stars-counter-star'})\n",
    "    \n",
    "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
    "\n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c2d83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    \n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3007f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_description(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa02493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    \n",
    "    os.makedirs('./scraped_repos', exist_ok=True)\n",
    "    \n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], './scraped_repos/{}.csv'.format(row['title']))\n",
    "        print('Scraping complete for \"{}\" repositories'.format(row['title']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b506e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "Scraping complete for \"3D\" repositories\n",
      "\n",
      "Scraping top repositories for \"Ajax\"\n",
      "Scraping complete for \"Ajax\" repositories\n",
      "\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "Scraping complete for \"Algorithm\" repositories\n",
      "\n",
      "Scraping top repositories for \"Amp\"\n",
      "Scraping complete for \"Amp\" repositories\n",
      "\n",
      "Scraping top repositories for \"Android\"\n",
      "Scraping complete for \"Android\" repositories\n",
      "\n",
      "Scraping top repositories for \"Angular\"\n",
      "Scraping complete for \"Angular\" repositories\n",
      "\n",
      "Scraping top repositories for \"Ansible\"\n",
      "Scraping complete for \"Ansible\" repositories\n",
      "\n",
      "Scraping top repositories for \"API\"\n",
      "Scraping complete for \"API\" repositories\n",
      "\n",
      "Scraping top repositories for \"Arduino\"\n",
      "Scraping complete for \"Arduino\" repositories\n",
      "\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "Scraping complete for \"ASP.NET\" repositories\n",
      "\n",
      "Scraping top repositories for \"Atom\"\n",
      "Scraping complete for \"Atom\" repositories\n",
      "\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "Scraping complete for \"Awesome Lists\" repositories\n",
      "\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "Scraping complete for \"Amazon Web Services\" repositories\n",
      "\n",
      "Scraping top repositories for \"Azure\"\n",
      "Scraping complete for \"Azure\" repositories\n",
      "\n",
      "Scraping top repositories for \"Babel\"\n",
      "Scraping complete for \"Babel\" repositories\n",
      "\n",
      "Scraping top repositories for \"Bash\"\n",
      "Scraping complete for \"Bash\" repositories\n",
      "\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "Scraping complete for \"Bitcoin\" repositories\n",
      "\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "Scraping complete for \"Bootstrap\" repositories\n",
      "\n",
      "Scraping top repositories for \"Bot\"\n",
      "Scraping complete for \"Bot\" repositories\n",
      "\n",
      "Scraping top repositories for \"C\"\n",
      "Scraping complete for \"C\" repositories\n",
      "\n",
      "Scraping top repositories for \"Chrome\"\n",
      "Scraping complete for \"Chrome\" repositories\n",
      "\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "Scraping complete for \"Chrome extension\" repositories\n",
      "\n",
      "Scraping top repositories for \"Command line interface\"\n",
      "Scraping complete for \"Command line interface\" repositories\n",
      "\n",
      "Scraping top repositories for \"Clojure\"\n",
      "Scraping complete for \"Clojure\" repositories\n",
      "\n",
      "Scraping top repositories for \"Code quality\"\n",
      "Scraping complete for \"Code quality\" repositories\n",
      "\n",
      "Scraping top repositories for \"Code review\"\n",
      "Scraping complete for \"Code review\" repositories\n",
      "\n",
      "Scraping top repositories for \"Compiler\"\n",
      "Scraping complete for \"Compiler\" repositories\n",
      "\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "Scraping complete for \"Continuous integration\" repositories\n",
      "\n",
      "Scraping top repositories for \"COVID-19\"\n",
      "Scraping complete for \"COVID-19\" repositories\n",
      "\n",
      "Scraping top repositories for \"C++\"\n",
      "Scraping complete for \"C++\" repositories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76135db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
